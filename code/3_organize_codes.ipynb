{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17857a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c0e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_true_code(file_path):\n",
    "    code_list = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "        # 按大分隔线分割不同的 key_action 部分\n",
    "        sections = content.split(\"=\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        for section in sections:\n",
    "            if not section.strip():\n",
    "                continue\n",
    "            code_content = []\n",
    "\n",
    "            # 按小分隔线分割代码块\n",
    "            blocks = section.split(\"=\"*20 + \"\\n\\n\")\n",
    "            for block in blocks:\n",
    "                if \"Result = True\" in block:\n",
    "                    # 找到 Code Block 开始和 Result 之间的内容\n",
    "                    lines = block.split('\\n')\n",
    "                    code_start = False\n",
    "                    \n",
    "                    for line in lines:\n",
    "                        if line.startswith(\"Code Block\"):\n",
    "                            code_start = True\n",
    "                            continue\n",
    "                        if line.startswith(\"Result =\"):\n",
    "                            break\n",
    "                        if code_start and line.strip():\n",
    "                            code_content.append(line)\n",
    "                    \n",
    "                    if code_content:\n",
    "                        code_list.append('\\n'.join(code_content))\n",
    "                        break\n",
    "            if not code_content:\n",
    "                code_list.append(False)\n",
    "    \n",
    "    return code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fff23ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(dir):\n",
    "    current_id = 1\n",
    "    all_key_nodes = []\n",
    "    all_tasks = {}\n",
    "    \n",
    "    with open(f'{dir}/tasks_and_key_nodes.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for name, details in data.items():\n",
    "        # if name != \"RecipeDeleteMultipleRecipes\":\n",
    "        #     continue\n",
    "        code_file_path = f\"{dir}/code_lists/{name}.txt\"\n",
    "        codes = extract_first_true_code(code_file_path)\n",
    "\n",
    "        node_ids = []\n",
    "        graph = {}\n",
    "        objective = details['objective']\n",
    "        template = details['template']\n",
    "        key_nodes = details['key_nodes']\n",
    "\n",
    "        for idx, key_node in enumerate(key_nodes):\n",
    "            # 检查是否已存在相同的 key_action\n",
    "            existing_node = next((node for node in all_key_nodes if node['description'] == key_node), None)\n",
    "            if existing_node:\n",
    "                # 如果存在，复用已有节点的 ID\n",
    "                node_ids.append(existing_node['id'])\n",
    "            else:\n",
    "                label_function = codes[idx]\n",
    "                if label_function != False:     # 只有验证成功的才会被创建和加入\n",
    "                    # 如果不存在，创建新节点\n",
    "                    node = {\n",
    "                        \"id\": str(current_id),\n",
    "                        \"description\": key_node,\n",
    "                        \"label_function\": label_function\n",
    "                    }\n",
    "                    all_key_nodes.append(node)\n",
    "                    node_ids.append(str(current_id))\n",
    "                    current_id += 1\n",
    "\n",
    "        # 生成图结构\n",
    "        for i, node_id in enumerate(node_ids):\n",
    "            # 设置为列表形式，方便之后添加节点\n",
    "            parent_node_id = [\"0\"] if i == 0 else [node_ids[i-1]]   # 第一个节点 parent 为 0\n",
    "            child_node_id = [\"-1\"] if i == len(node_ids)-1 else [node_ids[i+1]] # 最后一个节点 child 为 -1\n",
    "            graph[node_id] = {\n",
    "                \"parent_node_id\": parent_node_id,  \n",
    "                \"child_node_id\": child_node_id  \n",
    "            }\n",
    "\n",
    "        # 存储 objective 和 key_nodes\n",
    "        all_tasks[name] = {\n",
    "            \"objective\": objective,\n",
    "            \"template\": template,\n",
    "            \"key_nodes\": graph\n",
    "        }\n",
    "\n",
    "    with open(f\"{dir}/key_nodes.json\", 'w') as f:\n",
    "        json.dump(all_key_nodes, f, indent=4)\n",
    "    with open(f\"{dir}/tasks.json\", 'w') as f:\n",
    "        json.dump(all_tasks, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fb2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个之后还得额外写\n",
    "# 合并文件\n",
    "def merge_key_nodes(key1_path, key2_path, output_path):\n",
    "    # 读第一份 key_nodes\n",
    "    with open(key1_path, 'r', encoding='utf-8') as f:\n",
    "        key1 = json.load(f)\n",
    "    # 读第二份 key_nodes\n",
    "    with open(key2_path, 'r', encoding='utf-8') as f:\n",
    "        key2 = json.load(f)\n",
    "\n",
    "    # 建 description -> id 映射，用于检测重复\n",
    "    existing = { node['description']: node['id'] for node in key1}\n",
    "    # 计算第一份中的最大 id（数字）\n",
    "    max_id1 = max(int(node['id']) for node in key1)\n",
    "\n",
    "    merged = list(key1)     # 合并列表初始为第一份内容\n",
    "    id_mapping = {}         # 记录第二份旧 id -> 新 id（或已有 id）\n",
    "    next_id = max_id1       # 用于分配新 id 的游标\n",
    "\n",
    "    for node in key2:\n",
    "        old_id = node['id']\n",
    "        key = node['description']\n",
    "        if key in existing:\n",
    "            # 重复：复用已有 id\n",
    "            id_mapping[old_id] = existing[key]\n",
    "        else:\n",
    "            # 新节点：分配下一个 id\n",
    "            next_id += 1\n",
    "            new_id = str(next_id)\n",
    "            node['id'] = new_id\n",
    "            merged.append(node)\n",
    "            id_mapping[old_id] = new_id\n",
    "\n",
    "    # 写出合并后的 key_nodes_new.json\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    return id_mapping\n",
    "\n",
    "def merge_tasks(tasks1_path, tasks2_path, id_mapping, output_path):\n",
    "    # 读两份 tasks\n",
    "    with open(tasks1_path, 'r', encoding='utf-8') as f:\n",
    "        tasks1 = json.load(f)\n",
    "    with open(tasks2_path, 'r', encoding='utf-8') as f:\n",
    "        tasks2 = json.load(f)\n",
    "\n",
    "    merged = {}\n",
    "\n",
    "    # 先把 tasks1 的所有任务拷贝过去\n",
    "    for name, content in tasks1.items():\n",
    "        # 深拷贝一份，后面不改 key_nodes\n",
    "        merged[name] = content.copy()\n",
    "    \n",
    "    for name, content in tasks2.items():\n",
    "        print(\"原来的内容\")\n",
    "        print(content.get('key_nodes', {}))\n",
    "        # 更新 key_nodes 中的 id 引用\n",
    "        updated_key_nodes = {}\n",
    "        original_key_nodes = content.get('key_nodes', {})\n",
    "        for kn_id, kn_meta in original_key_nodes.items():\n",
    "            # 1. 获取map\n",
    "            mapped_kn_id = id_mapping.get(kn_id, kn_id)\n",
    "            \n",
    "            # 2. Create a copy\n",
    "            new_kn_meta = kn_meta.copy()\n",
    "\n",
    "            # 3. 处理 'parent_node_id' 的映射\n",
    "            if 'parent_node_id' in new_kn_meta:\n",
    "                mapped_parents = [id_mapping.get(p_id, p_id) for p_id in kn_meta['parent_node_id']]\n",
    "                new_kn_meta['parent_node_id'] = mapped_parents\n",
    "\n",
    "            # 4. 处理 'child_node_id' 的映射\n",
    "            if 'child_node_id' in new_kn_meta:\n",
    "                mapped_children = [id_mapping.get(c_id, c_id) for c_id in kn_meta['child_node_id']]\n",
    "                new_kn_meta['child_node_id'] = mapped_children\n",
    "            \n",
    "            # 5. Assign\n",
    "            updated_key_nodes[mapped_kn_id] = new_kn_meta\n",
    "\n",
    "        print(\"新内容\")\n",
    "        print(updated_key_nodes)\n",
    "        # 把原 content 复制一份，并替换 key_nodes\n",
    "        new_content = content.copy()\n",
    "        new_content['key_nodes'] = updated_key_nodes\n",
    "\n",
    "        merged[name] = new_content\n",
    "\n",
    "    # 写出合并后的 tasks_new.json\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(merged, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def merge_main(dir1, dir2):\n",
    "    # 合并文件\n",
    "    key1_json   = f'{dir1}/key_nodes.json'\n",
    "    key2_json   = f'{dir2}/key_nodes.json'\n",
    "    tasks1_json = f'{dir1}/tasks.json'\n",
    "    tasks2_json = f'{dir2}/tasks.json'\n",
    "    # 输出文件\n",
    "    merged_tasks = f'{dir2}/tasks.json'\n",
    "    merged_keys  = f'{dir2}/key_nodes.json'\n",
    "\n",
    "    # 1) 合并 key_nodes，获取 id 映射\n",
    "    id_map = merge_key_nodes(key1_json, key2_json, merged_keys)\n",
    "    # 2) 合并 tasks，只更新 key_nodes 引用，不改 task_id\n",
    "    merge_tasks(tasks1_json, tasks2_json, id_map, merged_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34687032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir = \"json_files/OS-Atlas/InnovAll/Iter3\"\n",
    "# initialize(dir)\n",
    "# dir_before = \"json_files/OS-Atlas/InnovAll/Iter2\"\n",
    "# merge_main(dir_before, dir)\n",
    "\n",
    "# dir = \"json_files/GUI-R1/InnovAll/Iter3\"\n",
    "# initialize(dir)\n",
    "# dir_before = \"json_files/GUI-R1/InnovAll/Iter2\"\n",
    "# merge_main(dir_before, dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_key_node(name, key_nodes, output_file, dir):\n",
    "    # Load existing data\n",
    "    with open(f\"{dir}/key_nodes.json\", 'r') as f:\n",
    "        all_key_nodes = json.load(f)\n",
    "    with open(f\"{dir}/tasks.json\", 'r') as f:\n",
    "        all_tasks = json.load(f)\n",
    "    \n",
    "    # Initialize variables\n",
    "    node_ids = []\n",
    "    new_graph = {}\n",
    "    code_file_path = f\"{output_file}/{name}.txt\"\n",
    "    \n",
    "    # Handle code extraction\n",
    "    codes = extract_first_true_code(code_file_path)\n",
    "    \n",
    "    # Get current max ID\n",
    "    current_id = max(int(node['id']) for node in all_key_nodes) + 1 if all_key_nodes else 1\n",
    "    \n",
    "    # Process new key nodes\n",
    "    for idx, key_node in enumerate(key_nodes):\n",
    "        # Check for existing node\n",
    "        # 这里要 .lower()防止出现重复\n",
    "        existing_node = next((node for node in all_key_nodes if node['description'].lower() == key_node.lower()), None)\n",
    "        if existing_node:\n",
    "            node_ids.append(existing_node['id'])\n",
    "        else:\n",
    "            label_function = codes[idx]\n",
    "            if label_function != False:     # 只有验证成功的才会被创建和加入\n",
    "                # 如果不存在，创建新节点\n",
    "                node = {\n",
    "                    \"id\": str(current_id),\n",
    "                    \"description\": key_node,\n",
    "                    \"label_function\": label_function\n",
    "                }\n",
    "                all_key_nodes.append(node)\n",
    "                node_ids.append(str(current_id))\n",
    "                current_id += 1\n",
    "    \n",
    "    # Create new graph structure\n",
    "    for i, node_id in enumerate(node_ids):\n",
    "        parent_node_id = [\"0\"] if i == 0 else [node_ids[i-1]]\n",
    "        child_node_id = [\"-1\"] if i == len(node_ids)-1 else [node_ids[i+1]]\n",
    "        new_graph[node_id] = {\n",
    "            \"parent_node_id\": parent_node_id,\n",
    "            \"child_node_id\": child_node_id\n",
    "        }\n",
    "\n",
    "    # Merge with existing graph\n",
    "    existing_graph = all_tasks[name][\"key_nodes\"]\n",
    "    print(\"existing_graph:\", existing_graph)\n",
    "    print(\"new_graph:\", new_graph)\n",
    "    merged_graph = {}\n",
    "\n",
    "    # 开始合并\n",
    "    # Combine all unique nodes\n",
    "    all_node_ids = set(existing_graph.keys()) | set(new_graph.keys())\n",
    "\n",
    "    for node_id in all_node_ids:\n",
    "        # Convert node_id to string for dictionary access\n",
    "        node_id = str(node_id)\n",
    "        \n",
    "        # Initialize parent and child lists\n",
    "        parent_nodes = []\n",
    "        child_nodes = []\n",
    "        \n",
    "        # Get parents and children from existing graph\n",
    "        if node_id in existing_graph:\n",
    "            parent_nodes.extend(existing_graph[node_id][\"parent_node_id\"])\n",
    "            child_nodes.extend(existing_graph[node_id][\"child_node_id\"])\n",
    "        \n",
    "        # Get parents and children from new graph\n",
    "        if node_id in new_graph:\n",
    "            parent_nodes.extend(new_graph[node_id][\"parent_node_id\"])\n",
    "            child_nodes.extend(new_graph[node_id][\"child_node_id\"])\n",
    "        \n",
    "        # Remove duplicates and maintain rules\n",
    "        parent_nodes = list(set(parent_nodes))\n",
    "        child_nodes = list(set(child_nodes))\n",
    "        \n",
    "        merged_graph[node_id] = {\n",
    "            \"parent_node_id\": parent_nodes,\n",
    "            \"child_node_id\": child_nodes\n",
    "        }\n",
    "\n",
    "    print(\"merged_graph:\", merged_graph)\n",
    "\n",
    "    # Update the task with merged graph\n",
    "    all_tasks[name][\"key_nodes\"] = merged_graph\n",
    "\n",
    "    # Save updated data\n",
    "    with open(f\"{dir}/key_nodes.json\", 'w') as f:\n",
    "        json.dump(all_key_nodes, f, indent=4)\n",
    "    with open(f\"{dir}/tasks.json\", 'w') as f:\n",
    "        json.dump(all_tasks, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "android_world",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
